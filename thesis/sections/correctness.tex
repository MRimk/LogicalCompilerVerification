\chapter{Compilation correctness}\label{s:correctness}
To have a complete compiler, I prove for each expression the correctness statement, which essentially means that the compiled expression executes as intended. 


\section{Arithmetic expressions}
The correctness of arithmetic expressions (like all correctness proofs) follows an induction on the arithmetic expression. Induction in this case, inspired by Isabelle proof, generalizes stack such that it could be specified in each induction hypothesis as needed (however, I don't ever use this). These induction cases can be split into two parts - numbers and variables, and operations with them because the proofs for these grouped cases are very similar. Isabelle proof is based on induction but is completed automatically by \emph{fastforce+}.

\begin{lstlisting}
lemma acomp_correct {a : aexp}  {s : state}  {stk : stack} :
exec (acomp a) (0, s, stk) (list.length (acomp a), s, (eval a s) :: stk)
\end{lstlisting}

\subsection{Numbers and variables}

Since the proofs for numbers (constants) and variables are very similar, they can be covered together. The compilation creates a list of a single instruction - \lstinline{LOADI} or \lstinline{LOAD}. This means that a single step execution is enough to verify a single instruction, therefore I use \lstinline{star.single} lemma to simplify the goal, and I use \lstinline{exec1I} lemma to create \lstinline{exec1 [LOADI a] (0, s, stk) (1, s, a :: stk)} subgoal (in the \lstinline{var} case it is \lstinline{[LOAD a]}).

\subsection{Operations with arithmetic expressions}

To prove the correctness of arithmetic operations I used \lstinline{star.trans} tactic twice to show how three lists are concatenated together. Both \lstinline{acomp a1} and \lstinline{acomp a2} compilations come from the respective inductive hypotheses, and the only part that I manually had to create was the arithmetic operator instruction (e.g. \lstinline{[DIV]}) execution itself. To create arithmetic instruction execution I could use \lstinline{star.single} lemma to transform multiple steps into one \lstinline{exec1} step and use \lstinline{exec1I} to create the goal execution.

\section{Boolean expressions}
Boolean expressions compilation correctness is based on induction where it generalizes \lstinline{f} (boolean flag) and \lstinline{n} (offset used in a jump instruction), with initial hypotheses being that \lstinline{0 ≤  n}. Having arbitrary flag and offset helps in proofs where the induction hypothesis (later $IH$) is very simple for separate executions and I need to create a sequential process out of those hypotheses, or I need to specify \lstinline{f}. All of the case proofs involve splitting the goal using \lstinline{by_cases} tactic or \lstinline{cases classical.em}, which create a true and false case for a boolean expression, which, in turn, eliminates \lstinline{ite} (if-then-else) in the goal.

\begin{lstlisting}
lemma bcomp_correct (n: ℤ) ( b f s stk)
(h_nneg : 0 ≤  n) :
exec (bcomp b f n) (0, s, stk) (list.length (bcomp b f n) + (if (f = bval b s) then n else 0), s, stk)
\end{lstlisting}

\subsection{Not}
In Isabelle, the \emph{Not} case is not completely automatic, but it explicitly specifies the \emph{f} to be \emph{$\sim$f} (not f), and then \emph{fastforce} completes the proof.

In Lean, the proof is more involved. Inspired by the Isabelle proof, I first specify $IH$ to use \lstinline{¬f} instead of \lstinline{f}. Then I split the if into true case and false case to simplify the goal. In the true case, where \lstinline{b} evaluates to be equal to \lstinline{f}, simplifying the goal and $IH$ is enough to get the same result, and in the false case simplifying is enough with a manual proof that not equals translates into one side is equal to negated other side (\lstinline{¬f = bval b s → f = ¬ bval b s}).

\subsection{And}
In Isabelle, the \emph{And} case is more specified than other proofs, meaning that the splitting of cases and $IH$ specification is explicitly defined. After these mentions, \emph{fastforce} automatic steps finishes the case.

In Lean, as in \lstinline{Not} case, I took inspiration of what explicit information Isabelle proof gave me and used it in my favor. As described in the Concrete Semantics \cite{isabelle}, the cases split is on \lstinline{f = true} since the jump after first part of execution depends on the \lstinline{f} (shown in the definition \ref{bexp}). In the true case of this split $IH$ is specified to have \lstinline{f} as false and \lstinline{n} as \lstinline{int.of_nat(list.length (bcomp b2 f n))}, whereas in the false case \lstinline{n} is \lstinline{ int.of_nat (list.length (bcomp b2 f n)) + n} (\lstinline{int.of_nat} is used because the length of a list is a natural number). In both cases, however, the proof follows the same structure but differs in small part due to the \lstinline{f} being true or false. Since the execution is of two instruction lists built during the boolean compilation, I use \lstinline{exec_append_trans} lemma to split the goal into smaller subgoals and to show how these two lists combine into one. The first list part is relatively easy to prove using specified $IH$ and the second part requires more details to get to the goal. The second part has an if-then-else in its goal program counter, which means that another case split on the value of the first \lstinline{And} part is created. In one of the cases, the first part is false, which means that the conjunction is false, so it jumps over the second part, making it a reflexive execution. In the other case, the jump depends on the second part being true or false, which means that it needs to be executed to get its value, thus there is no jump. The proof of the \lstinline{And} case is complex because it has to specify all these boolean values and cover all combinations.

\subsection{Less}

The \lstinline{Less} proof is constructed out of two applications of \lstinline{exec_append_trans} lemma to add together two arithmetic expressions and the jump command. To create arithmetic expressions I could use already proven \lstinline{acomp_correct} lemma, which makes the proof process easier. To create jump instructions I manually create an execution with an if-then-else, such that I could simplify it and prove it in smaller cases rather than combining cases bottom-up. The \lstinline{ite} simplification cases are of similar structure where \lstinline{exec} is transformed into \lstinline{exec1} by \lstinline{star.single} lemma, and then relevant comparison simplification is applied which is straightforward. 

In Isabelle, this is one of the cases of boolean compilation that is proven completely automatically by \emph{fastforce}.

\section{Commands}
The command correctness proof shows the correct representation of the source program in the machine program. This means that in the machine code it should cause the same state change and it should terminate if and only if the source program terminates. Termination can be expressed as a program counter reaching the end of the compiled expression, i.e. \lstinline{i = (ccomp c).length}, if it started from 0. In the same way, stack should not change.

The state change can be expressed as \lstinline{(c, s) ⟹ t}, which is called big-step operational semantics. This can be read as "Starting with the state s, executing c will terminate with a state t". I use modified big-step semantics defined from Hitchhiker's Guide \cite{hithchiker} that is used to create a minimalist imperative programming language interpreter. 

In the case of the compiler, the semantics matter when we want to be sure that the source code simulates compiled code - then every final state created by the compiled code is represented in the source code. Thus, we know that all compiled code is trusted if it terminates. To know that it terminates we need to prove that the compiled code represents correctly the source code \cite{isabelle}. I will do only the latter part which is easier \todo{say that i have not done the small-step semantics part and why} and it can be understood as follows: "if the source program executes from state s to state t, then the compiled program will as well." 

\begin{lstlisting}
lemma ccomp_bigstep {c : com} { s : state } {t : state } (stk : stack) 
(h_step : (c, s) ⟹ t) :
exec (ccomp c) (0, s, stk) (list.length (ccomp c), t, stk)
\end{lstlisting}

The proof of this lemma is by induction on big-step semantics \lstinline{h_step}. I use \lstinline{induction'} to generalize induction hypotheses (easier to use them) and to get cases that represent are from big-step semantics (splits into smaller cases which is also easier to work with).

\subsection{Assign}
The \lstinline{Assign} command is constructed out of arithmetic expression and \lstinline{STORE} instruction, so  \lstinline{exec_append_trans} lemma is applied to split the two in separate cases. The arithmetic expression can be proven by applying \lstinline{acomp_correct} lemma and for \lstinline{STORE} instruction \lstinline{star.single} lemma is used. To create the instruction, a hypothesis that matches the goal pattern is manually defined and simplified such that is true. This proof is relatively simple compared to other command cases, and that can also be seen in Isabelle, where this case is proven by \emph{fastforce} and \emph{simp}.

\subsection{Sequence}
The command \lstinline{Seq} is compiled out of two commands. In this case, in the proof for each of the commands, there is a relevant $IH$. These induction hypotheses are applied to show both commands in the \lstinline{exec_append_trans} application. Since these execution hypotheses are generalized in a way where they follow the transitive config (because of \lstinline{induction'}), there is no further work to be done.

In Isabelle, the proof follows the same structure by showing transitivity from the first part's start config to the second part's end config from induction hypotheses. These parts are joined together by automatic proof \emph{blast} which uses \emph{star\_trans}, which is essentially the same as using \lstinline{exec_append_trans} in Lean. 

\subsection{If}

\lstinline{If} is split into two true and false cases by the \lstinline{induction'} which made the proof easier to create and manage. Both cases follow a similar structure of connecting the condition to \emph{then} case or condition to \emph{else} case. Condition is created using \lstinline{bcomp_correct} lemma, but the resulting cases had to be manually defined. In the true case, there is another application of \lstinline{exec_append_trans} lemma to create a \emph{then} command compilation joined with a jump over \emph{else} case. Jump is proven with \lstinline{star.single} lemma and simplification, where the \emph{then} case is created from the $IH$. On the other hand, the false case, because it has a starting program counter position after \emph{then} case and the jump instruction, can be constructed using \lstinline{exec_appendL_if} lemma. This lemma states that if the program counter is more than or equal to the list, that is appended to the left, length, the execution continues in the initial list, in this case, the initial list being jump instruction concatenated to \emph{else} case. To skip the jump instruction \lstinline{exec_cons_1} lemma can be used, which states that if a single instruction is added to the left of the list, the execution continues in the initial list bounds but everything is shifted by 1. 

In Isabelle, this proof is completely automatic using \emph{fastforce+}.


\subsection{While}

The \lstinline{While} case proof is the most involved proof of this project. In Lean, the \lstinline{induction'} separates it into while true and while false cases. 

While false case is simple and similar to if \emph{else} case, where the condition is concatenated with something that does is skipped past. However, in the while loop, if the condition is false, the execution stops, so using \lstinline{exec_append_trans} lemma the boolean expression, which is created using \lstinline{bcomp_correct}, and execution of nothing, which is created with \lstinline{star.refl}, are connected together.

While true case is complex because it is a loop, so there are three executions to be connected and the loop execution itself. Inspired by Isabelle proof of \lstinline{While} case, I have defined all executions separately and then used \lstinline{exec_append_trans} to connect them. All three execution steps can probably be proven together, but separating them using \lstinline{exec_appendR} or \lstinline{exec_appendL} makes it easier to understand the goal and work towards it. The three steps of execution are condition, then while do part, and jumping back to the condition after do part is done. All of the steps are relatively simple when simplified from the initial goal because the initial list is puzzling to look at. In each step, I define manual equalities that I use to rewrite the goal to contain \lstinline{+ 0} or some negative list length because otherwise the \lstinline{exec_appendL} lemma would not work (it requires something to be added to the program counter, not only appended list). After simplifying the goals in each execution, condition is finished using \lstinline{bcomp_correct} lemma, while do section is finished using $IH$ of the singular execution, and jump back is finished with \lstinline{star.single} application. To complete the while, there is a the last part which is the loop execution itself, which is the compilation of the while. It might seem confusing why there is this execution of the while, but after a singular loop execution, the loop continues, thus it follows the singular execution. To prove the top-level while that follows individual execution steps, while $IH$ can be applied.